{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TalkNet Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea2ba0e1de8b4f4a94f6b2b1eb7eb049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c657e5345cca4fcabcda5162ef2291b1",
              "IPY_MODEL_634576fd2d4f4db796088b48f774b3a4",
              "IPY_MODEL_f5e9cff126a140109e37962d839bf954"
            ],
            "layout": "IPY_MODEL_00bc81afb10b49d9a12e823ecb362d44"
          }
        },
        "c657e5345cca4fcabcda5162ef2291b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a8dcfc91f204e6ba4bcf1fd44333936",
            "placeholder": "​",
            "style": "IPY_MODEL_2bb246bf88a546cbba9d6671d17daba9",
            "value": "100%"
          }
        },
        "634576fd2d4f4db796088b48f774b3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2237eb69fdd4c379ed6adf159f7f10d",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdb8715cf4b340db9f607f4b49853642",
            "value": 695
          }
        },
        "f5e9cff126a140109e37962d839bf954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8290b8626a04f5e83f31e04050b4605",
            "placeholder": "​",
            "style": "IPY_MODEL_70b9f51c46b541588c5092df154cee7c",
            "value": " 695/695 [00:56&lt;00:00, 12.22it/s]"
          }
        },
        "00bc81afb10b49d9a12e823ecb362d44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a8dcfc91f204e6ba4bcf1fd44333936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb246bf88a546cbba9d6671d17daba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2237eb69fdd4c379ed6adf159f7f10d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb8715cf4b340db9f607f4b49853642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8290b8626a04f5e83f31e04050b4605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b9f51c46b541588c5092df154cee7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalalune/LJSpeechTools/blob/main/TalkNet_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gss5Ox_RNiba"
      },
      "source": [
        "# TalkNet Training\n",
        "Last updated: 2022-05-20\n",
        "\n",
        "To train a 22KHz TalkNet, run the cells below and follow the instructions.\n",
        "\n",
        "This will take a while, and you might have to do it in multiple Colab sessions. The notebook will automatically resume training any models from the last saved checkpoint. If you're resuming from a new session, always re-run steps 1 through 5 first.\n",
        "\n",
        "##**IMPORTANT:** \n",
        "Your Trash folder on Drive will fill up with old checkpoints\n",
        "as you train the various models. Keep an eye on your Drive storage, and empty the trash if it starts to become full.\n",
        "\n",
        "- Fixes by justinjohn0306"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCqXqFgP2ri0",
        "cellView": "form",
        "outputId": "f980c6e6-b185-48aa-bcea-aa6c58b3251a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@markdown **Step 1:** Check which GPU you've been allocated.\n",
        "\n",
        "#@markdown You want a P100, V100 or T4. \n",
        "#@markdown If you get a P4 or K80, factory reset the runtime and try again.\n",
        "!nvidia-smi -L\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-3be85b1d-c07c-35a0-ea33-08a7517647a2)\n",
            "Mon Sep 19 00:25:37 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9TI-Q6m3qlx",
        "outputId": "a92296b6-182e-43c5-c16f-7322b3f6e10f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@markdown **Step 2:** Mount Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfSawDUD5tqv",
        "outputId": "b671273e-b047-4ade-84a5-c8b788059f31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@markdown **Step 3:** Configure training data paths. Upload the following to your Drive and change the paths below:\n",
        "#@markdown * A dataset of .wav files, packaged as a .zip or .tar file\n",
        "#@markdown * Training and validation filelists, in LJSpeech format with relative paths (note: ARPABET transcripts are not supported)\n",
        "#@markdown * An output path for checkpoints\n",
        "\n",
        "import os\n",
        "\n",
        "dataset = \"/content/drive/My Drive/dataset.zip\" #@param {type:\"string\"}\n",
        "train_filelist = \"/content/drive/My Drive/train_filelist.txt\" #@param {type:\"string\"}\n",
        "val_filelist = \"/content/drive/My Drive/val_filelist.txt\" #@param {type:\"string\"}\n",
        "output_dir = \"/content/drive/My Drive/talknet/juice\" #@param {type:\"string\"}\n",
        "assert os.path.exists(dataset), \"Cannot find dataset\"\n",
        "assert os.path.exists(train_filelist), \"Cannot find training filelist\"\n",
        "assert os.path.exists(val_filelist), \"Cannot find validation filelist\"\n",
        "if not os.path.exists(output_dir):\n",
        "   os.makedirs(output_dir)\n",
        "print(\"OK\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "f4poitziIsJI",
        "outputId": "9bc003b9-b8dc-4701-bc10-afb9cfab328a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teF-Ut8Z7Gjp",
        "cellView": "form",
        "outputId": "fa8fbd92-dcc4-4df4-9dad-ce00c913d09d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@markdown **Step 4:** Download NVIDIA NeMo.\n",
        "!pip install gdown --upgrade\n",
        "%tensorflow_version 2.x\n",
        "import os\n",
        "import time\n",
        "import gdown\n",
        "\n",
        "os.chdir('/content')\n",
        "!apt-get install sox libsndfile1 ffmpeg\n",
        "!pip install wget unidecode tensorflow==2.4.1 tensorboardX pysptk frozendict torch_stft torchvision==0.9.1 torchaudio==0.8.1 torchtext==0.9.1 pytorch-lightning==1.3.8 kaldiio pydub pyannote.audio g2p_en pesq pystoi crepe ffmpeg-python\n",
        "!python -m pip install git+https://github.com/SortAnon/NeMo.git\n",
        "!git clone -q https://github.com/SortAnon/hifi-gan.git\n",
        "\n",
        "!mkdir -p conf && cd conf \\\n",
        "&& wget https://raw.githubusercontent.com/SortAnon/NeMo/main/examples/tts/conf/talknet-durs.yaml \\\n",
        "&& wget https://raw.githubusercontent.com/SortAnon/NeMo/main/examples/tts/conf/talknet-pitch.yaml \\\n",
        "&& wget https://raw.githubusercontent.com/SortAnon/NeMo/main/examples/tts/conf/talknet-spect.yaml \\\n",
        "&& cd ..\n",
        "\n",
        "# Download pre-trained models\n",
        "zip_path = \"tts_en_talknet_1.0.0rc1.zip\"\n",
        "for i in range(10):\n",
        "    if not os.path.exists(zip_path) or os.stat(zip_path).st_size < 100:\n",
        "        gdown.download(\n",
        "            \"https://drive.google.com/uc?id=19wSym9mNEnmzLS9XdPlfNAW9_u-mP1hR\",\n",
        "            zip_path,\n",
        "            quiet=False,\n",
        "        )\n",
        "!unzip -qo {zip_path}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.5.1.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.5.1-py3-none-any.whl size=14951 sha256=2944d22098eac2f91a45a79a510b99ad6c21ff379b53238f14b5e8503ffb4863\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/ec/b0/a96d1d126183f98570a785e6bf8789fca559853a9260e928e1\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.5.1\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libsndfile1 is already the newest version (1.0.28-4ubuntu0.18.04.2).\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libmagic-mgc libmagic1 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox3\n",
            "Suggested packages:\n",
            "  file libsox-fmt-all\n",
            "The following NEW packages will be installed:\n",
            "  libmagic-mgc libmagic1 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox3 sox\n",
            "0 upgraded, 8 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 760 kB of archives.\n",
            "After this operation, 6,717 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrnb0 amd64 0.1.3-2.1 [92.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrwb0 amd64 0.1.3-2.1 [45.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox3 amd64 14.4.2-3ubuntu0.18.04.1 [226 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2-3ubuntu0.18.04.1 [10.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-base amd64 14.4.2-3ubuntu0.18.04.1 [32.1 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 sox amd64 14.4.2-3ubuntu0.18.04.1 [101 kB]\n",
            "Fetched 760 kB in 1s (746 kB/s)\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 155569 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "Preparing to unpack .../2-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../3-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../4-libsox3_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../5-libsox-fmt-alsa_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../6-libsox-fmt-base_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../7-sox_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow==2.4.1\n",
            "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 15 kB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 52.0 MB/s \n",
            "\u001b[?25hCollecting pysptk\n",
            "  Downloading pysptk-0.1.21.tar.gz (420 kB)\n",
            "\u001b[K     |████████████████████████████████| 420 kB 52.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting frozendict\n",
            "  Downloading frozendict-2.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.9 MB/s \n",
            "\u001b[?25hCollecting torch_stft\n",
            "  Downloading torch_stft-0.1.4-py3-none-any.whl (6.2 kB)\n",
            "Collecting torchvision==0.9.1\n",
            "  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 207 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.1\n",
            "  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 32.6 MB/s \n",
            "\u001b[?25hCollecting torchtext==0.9.1\n",
            "  Downloading torchtext-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 9.7 MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning==1.3.8\n",
            "  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\n",
            "\u001b[K     |████████████████████████████████| 813 kB 51.4 MB/s \n",
            "\u001b[?25hCollecting kaldiio\n",
            "  Downloading kaldiio-2.17.2.tar.gz (24 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting pyannote.audio\n",
            "  Downloading pyannote.audio-2.0.1-py2.py3-none-any.whl (385 kB)\n",
            "\u001b[K     |████████████████████████████████| 385 kB 48.2 MB/s \n",
            "\u001b[?25hCollecting g2p_en\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 41.7 MB/s \n",
            "\u001b[?25hCollecting pesq\n",
            "  Downloading pesq-0.0.4.tar.gz (38 kB)\n",
            "Collecting pystoi\n",
            "  Downloading pystoi-0.3.3.tar.gz (7.0 kB)\n",
            "Collecting crepe\n",
            "  Downloading crepe-0.0.12.tar.gz (15 kB)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.8.0)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 44.0 MB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.1)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 35.2 MB/s \n",
            "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 54.0 MB/s \n",
            "\u001b[?25hCollecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Collecting numpy~=1.19.2\n",
            "  Using cached numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1) (7.1.2)\n",
            "Collecting torch==1.8.1\n",
            "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1 MB 2.9 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1) (2.23.0)\n",
            "Collecting pyDeprecate==0.3.0\n",
            "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (2022.8.2)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 46.9 MB/s \n",
            "\u001b[?25hCollecting PyYAML<=5.4.1,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 46.6 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.2.0\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 35.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (21.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8) (3.8.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8) (1.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning==1.3.8) (3.0.9)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from pysptk) (4.4.2)\n",
            "Requirement already satisfied: cython>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from pysptk) (0.29.32)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pysptk) (1.7.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from torch_stft) (0.8.1)\n",
            "Collecting pytorch-metric-learning<2.0,>=1.0.0\n",
            "  Downloading pytorch_metric_learning-1.6.0-py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 46.5 MB/s \n",
            "\u001b[?25hCollecting pyannote.metrics<4.0,>=3.2\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 189 kB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx<3.0,>=2.6 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio) (2.6.3)\n",
            "Requirement already satisfied: soundfile<0.11,>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio) (0.10.3.post1)\n",
            "Collecting pyannote.audio\n",
            "  Downloading pyannote.audio-1.1.2-py3-none-any.whl (231 kB)\n",
            "\u001b[K     |████████████████████████████████| 231 kB 18.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio) (1.3.5)\n",
            "Collecting pyannote.pipeline<2.0.0,>=1.5.2\n",
            "  Downloading pyannote.pipeline-1.5.2-py3-none-any.whl (25 kB)\n",
            "Collecting pyannote.core>=4.1\n",
            "  Downloading pyannote.core-4.5-py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio) (2.4.0)\n",
            "Collecting pescador>=2.1.0\n",
            "  Downloading pescador-2.1.0.tar.gz (20 kB)\n",
            "Collecting pyannote.database>=4.0\n",
            "  Downloading pyannote.database-4.1.3-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 527 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio) (1.0.2)\n",
            "Collecting sortedcollections>=1.0.1\n",
            "  Downloading sortedcollections-2.1.0-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->torch_stft) (1.1.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->torch_stft) (3.0.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->torch_stft) (1.6.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->torch_stft) (0.4.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa->torch_stft) (0.56.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->torch_stft) (0.39.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->pyannote.audio) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->pyannote.audio) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=15.0 in /usr/local/lib/python3.7/dist-packages (from pescador>=2.1.0->pyannote.audio) (23.2.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->torch_stft) (1.4.4)\n",
            "Collecting simplejson>=3.8.1\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typer[all]>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.database>=4.0->pyannote.audio) (0.4.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pyannote.metrics<4.0,>=3.2->pyannote.audio) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from pyannote.metrics<4.0,>=3.2->pyannote.audio) (0.8.10)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.metrics<4.0,>=3.2->pyannote.audio) (1.7.1)\n",
            "Collecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio) (0.11.0)\n",
            "Requirement already satisfied: filelock>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (3.8.0)\n",
            "Collecting optuna>=1.4\n",
            "  Downloading optuna-3.0.2-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 49.7 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.9 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 48.8 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (1.4.41)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (5.9.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.2-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.2->pyannote.audio) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile<0.11,>=0.10.2->pyannote.audio) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile<0.11,>=0.10.2->pyannote.audio) (2.21)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (1.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.1->pyannote.metrics<4.0,>=3.2->pyannote.audio) (1.2.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer[all]>=0.2.1->pyannote.database>=4.0->pyannote.audio) (7.1.2)\n",
            "Collecting colorama<0.5.0,>=0.4.3\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0\n",
            "  Downloading shellingham-1.5.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.7/dist-packages (from g2p_en) (3.7)\n",
            "Collecting distance>=0.1.3\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 55.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from g2p_en) (2.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.4->g2p_en) (2022.6.2)\n",
            "Collecting resampy>=0.2.2\n",
            "  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
            "\u001b[K     |████████████████████████████████| 323 kB 51.9 MB/s \n",
            "\u001b[?25hCollecting hmmlearn<0.3.0,>=0.2.0\n",
            "  Downloading hmmlearn-0.2.7-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 43.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from crepe) (2.9.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.10.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 49.6 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (3.4.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (2.0.1)\n",
            "Building wheels for collected packages: future, wrapt, wget, pysptk, kaldiio, pescador, docopt, distance, pesq, pystoi, crepe, resampy, pyperclip\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=3bf98f157fbd1891ab23fbfb7784828ff35ce193da407ea924ac3518166f4510\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68701 sha256=b23faf9b819e9672408ec568025c99670f229400153b940508f36b3eb84d9767\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=8343e9815097269f09a03e5a117f3e078751e146b47a02f289af6d41533f3919\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "  Building wheel for pysptk (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysptk: filename=pysptk-0.1.21-cp37-cp37m-linux_x86_64.whl size=952306 sha256=61cd0f7df663051a2f8a1d79051541b7c90768a395e234a9a323b768bdac69d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/3d/14/d7179b072549e93b6b5d76eb8b455f3a9d39a10f314660a385\n",
            "  Building wheel for kaldiio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaldiio: filename=kaldiio-2.17.2-py3-none-any.whl size=24471 sha256=48793986ce103e363541139f6d1b5dd573bebbe299d617145b7426afb91fb638\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/07/e8/45641287c59bf6ce41e22259f8680b521c31e6306cb88392ac\n",
            "  Building wheel for pescador (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pescador: filename=pescador-2.1.0-py3-none-any.whl size=21105 sha256=ad74fba4089016a669ad3d11a4bc34451c3c5b87bb72c20004540b23e8b610ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/e3/c6/32d30d5eb5292dac352d2fca4ebf393aa94e09b9b8b4b0f341\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=b1debc0f486624459af9bcefa46f76f195e7bede5be3755d5ef7c874a04deee0\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16276 sha256=4edd6ee858e71b6880b1b7af3c752c4233bada38a43426aa4ed86cbf238d813d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/10/1b/96fca621a1be378e2fe104cfb0d160bb6cdf3d04a3d35266cc\n",
            "  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pesq: filename=pesq-0.0.4-cp37-cp37m-linux_x86_64.whl size=214588 sha256=92cf3eb7be9e22511e3ed16c00875c32ccd276f4850538fde50be9f8ed775226\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/3d/9c/542731f8357f7c82eb6ac2047cc5375f92c9a05b09a715aff6\n",
            "  Building wheel for pystoi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pystoi: filename=pystoi-0.3.3-py2.py3-none-any.whl size=7793 sha256=53879ce661503e4c9c45fb53533cd5dea2e40f5957ef4966f785c9fee8142844\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/4a/ad/3ab460193ed0535430b4b1575f255aa6bae69df17453628e86\n",
            "  Building wheel for crepe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crepe: filename=crepe-0.0.12-py3-none-any.whl size=134848696 sha256=aa582d59f507685e4f7c8de6adbe1a638d04d455c11ec7d525f413ade055bc06\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/05/32/fccf64e8ae720b34b486b6a8a08712777fd0beab419980fea3\n",
            "  Building wheel for resampy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320732 sha256=cd1592a41b2b1211f4d452874636d184ad6e58bd36c5b337b0493a5e706bffd2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/18/0a/8ad18a597d8333a142c9789338a96a6208f1198d290ece356c\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=b3200279bf0000aef78f7798a2fc2f78890eeb0f1f7025cd03068974969d4ddc\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built future wrapt wget pysptk kaldiio pescador docopt distance pesq pystoi crepe resampy pyperclip\n",
            "Installing collected packages: typing-extensions, pyperclip, pbr, numpy, stevedore, simplejson, shellingham, PyYAML, Mako, colorama, cmd2, autopage, pyannote.core, colorlog, cmaes, cliff, alembic, torch, resampy, pyannote.database, optuna, grpcio, docopt, absl-py, wrapt, torchmetrics, tensorflow-estimator, sortedcollections, pyDeprecate, pyannote.pipeline, pyannote.metrics, pescador, hmmlearn, h5py, gast, future, flatbuffers, distance, wget, unidecode, torchvision, torchtext, torchaudio, torch-stft, tensorflow, tensorboardX, pytorch-lightning, pystoi, pysptk, pydub, pyannote.audio, pesq, kaldiio, g2p-en, frozendict, ffmpeg-python, crepe\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: resampy\n",
            "    Found existing installation: resampy 0.4.0\n",
            "    Uninstalling resampy-0.4.0:\n",
            "      Successfully uninstalled resampy-0.4.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.48.1\n",
            "    Uninstalling grpcio-1.48.1:\n",
            "      Successfully uninstalled grpcio-1.48.1\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.2.0\n",
            "    Uninstalling absl-py-1.2.0:\n",
            "      Successfully uninstalled absl-py-1.2.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0.7\n",
            "    Uninstalling flatbuffers-2.0.7:\n",
            "      Successfully uninstalled flatbuffers-2.0.7\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.3.17 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.2.2 PyYAML-5.4.1 absl-py-0.15.0 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.2 colorama-0.4.5 colorlog-6.7.0 crepe-0.0.12 distance-0.1.3 docopt-0.6.2 ffmpeg-python-0.2.0 flatbuffers-1.12 frozendict-2.3.4 future-0.18.2 g2p-en-2.1.0 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 hmmlearn-0.2.7 kaldiio-2.17.2 numpy-1.19.5 optuna-3.0.2 pbr-5.10.0 pescador-2.1.0 pesq-0.0.4 pyDeprecate-0.3.0 pyannote.audio-1.1.2 pyannote.core-4.5 pyannote.database-4.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-1.5.2 pydub-0.25.1 pyperclip-1.8.2 pysptk-0.1.21 pystoi-0.3.3 pytorch-lightning-1.3.8 resampy-0.2.2 shellingham-1.5.0 simplejson-3.17.6 sortedcollections-2.1.0 stevedore-3.5.0 tensorboardX-2.5.1 tensorflow-2.4.1 tensorflow-estimator-2.4.0 torch-1.8.1 torch-stft-0.1.4 torchaudio-0.8.1 torchmetrics-0.9.3 torchtext-0.9.1 torchvision-0.9.1 typing-extensions-3.7.4.3 unidecode-1.3.4 wget-3.2 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/SortAnon/NeMo.git\n",
            "  Cloning https://github.com/SortAnon/NeMo.git to /tmp/pip-req-build-jjnke9_0\n",
            "  Running command git clone -q https://github.com/SortAnon/NeMo.git /tmp/pip-req-build-jjnke9_0\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from nemo-toolkit==1.0.2) (1.19.5)\n",
            "Collecting onnx>=1.7.0\n",
            "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytorch-lightning>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from nemo-toolkit==1.0.2) (1.3.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from nemo-toolkit==1.0.2) (2.8.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from nemo-toolkit==1.0.2) (1.8.1)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (from nemo-toolkit==1.0.2) (3.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from nemo-toolkit==1.0.2) (1.12.1)\n",
            "Collecting ruamel.yaml\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from nemo-toolkit==1.0.2) (1.0.2)\n",
            "Collecting omegaconf>=2.1.0\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting hydra-core>=1.1.0\n",
            "  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 53.3 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.0.1\n",
            "  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 43.2 MB/s \n",
            "\u001b[?25hCollecting sentencepiece<1.0.0\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 34.4 MB/s \n",
            "\u001b[?25hCollecting webdataset<=0.1.62,>=0.1.48\n",
            "  Downloading webdataset-0.1.62-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from nemo-toolkit==1.0.2) (4.64.1)\n",
            "Collecting opencc\n",
            "  Downloading OpenCC-1.1.4-cp37-cp37m-manylinux1_x86_64.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 49.2 MB/s \n",
            "\u001b[?25hCollecting pangu\n",
            "  Downloading pangu-4.0.6.1-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from nemo-toolkit==1.0.2) (0.42.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from nemo-toolkit==1.0.2) (0.56.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1.0->nemo-toolkit==1.0.2) (21.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1.0->nemo-toolkit==1.0.2) (5.9.0)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf>=2.1.0->nemo-toolkit==1.0.2) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.7.0->nemo-toolkit==1.0.2) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.7.0->nemo-toolkit==1.0.2) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.12.2->onnx>=1.7.0->nemo-toolkit==1.0.2) (1.15.0)\n",
            "Requirement already satisfied: pillow!=8.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (7.1.2)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (2.8.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (0.18.2)\n",
            "Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (0.3.0)\n",
            "Requirement already satisfied: torchmetrics>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (0.9.3)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (2022.8.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (2.23.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (1.8.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (1.3.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core>=1.1.0->nemo-toolkit==1.0.2) (3.0.9)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (0.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (1.32.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (0.37.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo-toolkit==1.0.2) (3.2.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 25.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.1->nemo-toolkit==1.0.2) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.1->nemo-toolkit==1.0.2) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 51.1 MB/s \n",
            "\u001b[?25hCollecting braceexpand\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->nemo-toolkit==1.0.2) (0.39.1)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->nemo-toolkit==1.0.2) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->nemo-toolkit==1.0.2) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->nemo-toolkit==1.0.2) (3.1.0)\n",
            "Building wheels for collected packages: nemo-toolkit, antlr4-python3-runtime\n",
            "  Building wheel for nemo-toolkit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nemo-toolkit: filename=nemo_toolkit-1.0.2-py3-none-any.whl size=1280168 sha256=b34c569e62274fa91c875c5a591e179df6f3f500ffecf88a70ebff8b0666ccd3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n6ujtvy8/wheels/cf/ce/5e/66f1ab00f11caab90d78ddd4496c37312408ceed2a8c30e9b8\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=e6befa4ed17bb5f6a38d30f8d8f68ef69939eb09200a9c05659e3fd9ab5db460\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "Successfully built nemo-toolkit antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, tokenizers, ruamel.yaml.clib, omegaconf, huggingface-hub, braceexpand, webdataset, transformers, sentencepiece, ruamel.yaml, pangu, opencc, onnx, hydra-core, nemo-toolkit\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 braceexpand-0.1.7 huggingface-hub-0.9.1 hydra-core-1.2.0 nemo-toolkit-1.0.2 omegaconf-2.2.3 onnx-1.12.0 opencc-1.1.4 pangu-4.0.6.1 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 sentencepiece-0.1.97 tokenizers-0.12.1 transformers-4.22.1 webdataset-0.1.62\n",
            "--2022-09-19 00:56:22--  https://raw.githubusercontent.com/SortAnon/NeMo/main/examples/tts/conf/talknet-durs.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3652 (3.6K) [text/plain]\n",
            "Saving to: ‘talknet-durs.yaml’\n",
            "\n",
            "talknet-durs.yaml   100%[===================>]   3.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-19 00:56:22 (39.3 MB/s) - ‘talknet-durs.yaml’ saved [3652/3652]\n",
            "\n",
            "--2022-09-19 00:56:22--  https://raw.githubusercontent.com/SortAnon/NeMo/main/examples/tts/conf/talknet-pitch.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3772 (3.7K) [text/plain]\n",
            "Saving to: ‘talknet-pitch.yaml’\n",
            "\n",
            "talknet-pitch.yaml  100%[===================>]   3.68K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-19 00:56:22 (50.5 MB/s) - ‘talknet-pitch.yaml’ saved [3772/3772]\n",
            "\n",
            "--2022-09-19 00:56:22--  https://raw.githubusercontent.com/SortAnon/NeMo/main/examples/tts/conf/talknet-spect.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5118 (5.0K) [text/plain]\n",
            "Saving to: ‘talknet-spect.yaml’\n",
            "\n",
            "talknet-spect.yaml  100%[===================>]   5.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-19 00:56:22 (49.8 MB/s) - ‘talknet-spect.yaml’ saved [5118/5118]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19wSym9mNEnmzLS9XdPlfNAW9_u-mP1hR\n",
            "To: /content/tts_en_talknet_1.0.0rc1.zip\n",
            "100%|██████████| 51.2M/51.2M [00:00<00:00, 108MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##**Run this cell and restart the runtime then run step 3**\n",
        "!pip install -q numpy --upgrade\n",
        "!pip install -q torchmetrics==0.6.0\n",
        "!pip install -q omegaconf==2.1.0"
      ],
      "metadata": {
        "id": "b7_kvmTw51q0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxFr3Fdi_kOC",
        "outputId": "57777c44-596c-47e8-dcbd-59c3b5fd480a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "ea2ba0e1de8b4f4a94f6b2b1eb7eb049",
            "c657e5345cca4fcabcda5162ef2291b1",
            "634576fd2d4f4db796088b48f774b3a4",
            "f5e9cff126a140109e37962d839bf954",
            "00bc81afb10b49d9a12e823ecb362d44",
            "9a8dcfc91f204e6ba4bcf1fd44333936",
            "2bb246bf88a546cbba9d6671d17daba9",
            "c2237eb69fdd4c379ed6adf159f7f10d",
            "fdb8715cf4b340db9f607f4b49853642",
            "d8290b8626a04f5e83f31e04050b4605",
            "70b9f51c46b541588c5092df154cee7c"
          ]
        }
      },
      "source": [
        "#@markdown **Step 5:** Dataset processing, part 1.\n",
        "\n",
        "#@markdown If this step fails, try the following:\n",
        "#@markdown * Make sure your filelists are correct. They should have relative \n",
        "#@markdown paths that match the contents of the archive.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import json\n",
        "import nemo\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from pysptk import sptk\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "import ffmpeg\n",
        "\n",
        "def fix_transcripts(inpath):\n",
        "    found_arpabet = False\n",
        "    found_grapheme = False\n",
        "    with open(inpath, \"r\", encoding=\"utf8\") as f:\n",
        "        lines = f.readlines()\n",
        "    with open(inpath, \"w\", encoding=\"utf8\") as f:\n",
        "        for l in lines:\n",
        "            if l.strip() == \"\":\n",
        "                continue\n",
        "            if \"{\" in l:\n",
        "                if not found_arpabet:\n",
        "                    print(\"Warning: Skipping ARPABET lines (not supported).\")\n",
        "                    found_arpabet = True\n",
        "            else:\n",
        "                f.write(l)\n",
        "                found_grapheme = True\n",
        "    assert found_grapheme, \"No non-ARPABET lines found in \" + inpath\n",
        "\n",
        "def generate_json(inpath, outpath):\n",
        "    output = \"\"\n",
        "    sample_rate = 22050\n",
        "    with open(inpath, \"r\", encoding=\"utf8\") as f:\n",
        "        for l in f.readlines():\n",
        "            lpath = l.split(\"|\")[0].strip()\n",
        "            size = os.stat(\n",
        "                os.path.join(os.path.dirname(inpath), lpath)\n",
        "            ).st_size\n",
        "            x = {\n",
        "                \"audio_filepath\": lpath,\n",
        "                \"duration\": size / (sample_rate * 2),\n",
        "                \"text\": l.split(\"|\")[1].strip(),\n",
        "            }\n",
        "            output += json.dumps(x) + \"\\n\"\n",
        "        with open(outpath, \"w\", encoding=\"utf8\") as w:\n",
        "            w.write(output)\n",
        "\n",
        "def convert_to_22k(inpath):\n",
        "    if inpath.strip()[-4:].lower() != \".wav\":\n",
        "        print(\"Warning: \" + inpath.strip() + \" is not a .wav file!\")\n",
        "        return\n",
        "    ffmpeg.input(inpath).output(\n",
        "        inpath + \"_22k.wav\",\n",
        "        ar=\"22050\",\n",
        "        ac=\"1\",\n",
        "        acodec=\"pcm_s16le\",\n",
        "        map_metadata=\"-1\",\n",
        "        fflags=\"+bitexact\",\n",
        "    ).overwrite_output().run(quiet=True)\n",
        "    os.remove(inpath)\n",
        "    os.rename(inpath + \"_22k.wav\", inpath)\n",
        "\n",
        "# Extract dataset\n",
        "os.chdir('/content')\n",
        "if os.path.exists(\"/content/wavs\"):\n",
        "    shutil.rmtree(\"/content/wavs\")\n",
        "os.mkdir(\"wavs\")\n",
        "os.chdir(\"wavs\")\n",
        "if dataset[-4:] == \".zip\":\n",
        "    !unzip -q \"{dataset}\"\n",
        "elif dataset[-4:] == \".tar\":\n",
        "    !tar -xf \"{dataset}\"\n",
        "else:\n",
        "    raise Exception(\"Unknown extension for dataset\")\n",
        "if os.path.exists(\"/content/wavs/wavs\"):\n",
        "    shutil.move(\"/content/wavs/wavs\", \"/content/tempwavs\")\n",
        "    shutil.rmtree(\"/content/wavs\")\n",
        "    shutil.move(\"/content/tempwavs\", \"/content/wavs\")\n",
        "\n",
        "# Filelist for preprocessing\n",
        "os.chdir('/content')\n",
        "shutil.copy(train_filelist, \"trainfiles.txt\")\n",
        "shutil.copy(val_filelist, \"valfiles.txt\")\n",
        "fix_transcripts(\"trainfiles.txt\")\n",
        "fix_transcripts(\"valfiles.txt\")\n",
        "seen_files = []\n",
        "with open(\"trainfiles.txt\") as f:\n",
        "    t = f.read().split(\"\\n\")\n",
        "with open(\"valfiles.txt\") as f:\n",
        "    v = f.read().split(\"\\n\")\n",
        "    all_filelist = t[:] + v[:]\n",
        "with open(\"/content/allfiles.txt\", \"w\") as f:\n",
        "    for x in all_filelist:\n",
        "        if x.strip() == \"\":\n",
        "            continue\n",
        "        if x.split(\"|\")[0] not in seen_files:\n",
        "            seen_files.append(x.split(\"|\")[0])\n",
        "            f.write(x.strip() + \"\\n\")\n",
        "\n",
        "# Ensure audio is 22k\n",
        "print(\"Converting audio...\")\n",
        "for r, _, f in os.walk(\"/content/wavs\"):\n",
        "    for name in tqdm(f):\n",
        "        convert_to_22k(os.path.join(r, name))\n",
        "\n",
        "# Convert to JSON\n",
        "generate_json(\"/content/trainfiles.txt\", \"/content/trainfiles.json\")\n",
        "generate_json(\"/content/valfiles.txt\", \"/content/valfiles.json\")\n",
        "generate_json(\"/content/allfiles.txt\", \"/content/allfiles.json\")\n",
        "\n",
        "print(\"OK\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting audio...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/695 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea2ba0e1de8b4f4a94f6b2b1eb7eb049"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sos9vsxPkIN7",
        "cellView": "form"
      },
      "source": [
        "#@markdown **Step 6:** Dataset processing, part 2. This takes a while, but\n",
        "#@markdown you only have to run this once per dataset (results are saved to Drive).\n",
        "\n",
        "#@markdown If this step fails, try the following:\n",
        "#@markdown * Make sure your dataset only contains WAV files.\n",
        "\n",
        "# Extract phoneme duration\n",
        "\n",
        "import json\n",
        "from nemo.collections.asr.models import EncDecCTCModel\n",
        "asr_model = EncDecCTCModel.from_pretrained(model_name=\"asr_talknet_aligner\").cpu().eval()\n",
        "\n",
        "def forward_extractor(tokens, log_probs, blank):\n",
        "    \"\"\"Computes states f and p.\"\"\"\n",
        "    n, m = len(tokens), log_probs.shape[0]\n",
        "    # `f[s, t]` -- max sum of log probs for `s` first codes\n",
        "    # with `t` first timesteps with ending in `tokens[s]`.\n",
        "    f = np.empty((n + 1, m + 1), dtype=float)\n",
        "    f.fill(-(10 ** 9))\n",
        "    p = np.empty((n + 1, m + 1), dtype=int)\n",
        "    f[0, 0] = 0.0  # Start\n",
        "    for s in range(1, n + 1):\n",
        "        c = tokens[s - 1]\n",
        "        for t in range((s + 1) // 2, m + 1):\n",
        "            f[s, t] = log_probs[t - 1, c]\n",
        "            # Option #1: prev char is equal to current one.\n",
        "            if s == 1 or c == blank or c == tokens[s - 3]:\n",
        "                options = f[s : (s - 2 if s > 1 else None) : -1, t - 1]\n",
        "            else:  # Is not equal to current one.\n",
        "                options = f[s : (s - 3 if s > 2 else None) : -1, t - 1]\n",
        "            f[s, t] += np.max(options)\n",
        "            p[s, t] = np.argmax(options)\n",
        "    return f, p\n",
        "\n",
        "\n",
        "def backward_extractor(f, p):\n",
        "    \"\"\"Computes durs from f and p.\"\"\"\n",
        "    n, m = f.shape\n",
        "    n -= 1\n",
        "    m -= 1\n",
        "    durs = np.zeros(n, dtype=int)\n",
        "    if f[-1, -1] >= f[-2, -1]:\n",
        "        s, t = n, m\n",
        "    else:\n",
        "        s, t = n - 1, m\n",
        "    while s > 0:\n",
        "        durs[s - 1] += 1\n",
        "        s -= p[s, t]\n",
        "        t -= 1\n",
        "    assert durs.shape[0] == n\n",
        "    assert np.sum(durs) == m\n",
        "    assert np.all(durs[1::2] > 0)\n",
        "    return durs\n",
        "\n",
        "def preprocess_tokens(tokens, blank):\n",
        "    new_tokens = [blank]\n",
        "    for c in tokens:\n",
        "        new_tokens.extend([c, blank])\n",
        "    tokens = new_tokens\n",
        "    return tokens\n",
        "\n",
        "data_config = {\n",
        "    'manifest_filepath': \"allfiles.json\",\n",
        "    'sample_rate': 22050,\n",
        "    'labels': asr_model.decoder.vocabulary,\n",
        "    'batch_size': 1,\n",
        "}\n",
        "\n",
        "parser = nemo.collections.asr.data.audio_to_text.AudioToCharWithDursF0Dataset.make_vocab(\n",
        "    notation='phonemes', punct=True, spaces=True, stresses=False, add_blank_at=\"last\"\n",
        ")\n",
        "\n",
        "dataset = nemo.collections.asr.data.audio_to_text._AudioTextDataset(\n",
        "    manifest_filepath=data_config['manifest_filepath'], sample_rate=data_config['sample_rate'], parser=parser,\n",
        ")\n",
        "\n",
        "dl = torch.utils.data.DataLoader(\n",
        "    dataset=dataset, batch_size=data_config['batch_size'], collate_fn=dataset.collate_fn, shuffle=False,\n",
        ")\n",
        "\n",
        "blank_id = asr_model.decoder.num_classes_with_blank - 1\n",
        "\n",
        "if os.path.exists(os.path.join(output_dir, \"durations.pt\")):\n",
        "    print(\"durations.pt already exists; skipping\")\n",
        "else:\n",
        "    dur_data = {}\n",
        "    for sample_idx, test_sample in tqdm(enumerate(dl), total=len(dl)):\n",
        "        log_probs, _, greedy_predictions = asr_model(\n",
        "            input_signal=test_sample[0], input_signal_length=test_sample[1]\n",
        "        )\n",
        "\n",
        "        log_probs = log_probs[0].cpu().detach().numpy()\n",
        "        seq_ids = test_sample[2][0].cpu().detach().numpy()\n",
        "\n",
        "        target_tokens = preprocess_tokens(seq_ids, blank_id)\n",
        "\n",
        "        f, p = forward_extractor(target_tokens, log_probs, blank_id)\n",
        "        durs = backward_extractor(f, p)\n",
        "\n",
        "        dur_key = Path(dl.dataset.collection[sample_idx].audio_file).stem\n",
        "        dur_data[dur_key] = {\n",
        "            'blanks': torch.tensor(durs[::2], dtype=torch.long).cpu().detach(), \n",
        "            'tokens': torch.tensor(durs[1::2], dtype=torch.long).cpu().detach()\n",
        "        }\n",
        "\n",
        "        del test_sample\n",
        "\n",
        "    torch.save(dur_data, os.path.join(output_dir, \"durations.pt\"))\n",
        "\n",
        "#Extract F0 (pitch)\n",
        "import crepe\n",
        "from scipy.io import wavfile\n",
        "\n",
        "def crepe_f0(audio_file, hop_length=256):\n",
        "    sr, audio = wavfile.read(audio_file)\n",
        "    audio_x = np.arange(0, len(audio)) / 22050.0\n",
        "    time, frequency, confidence, activation = crepe.predict(audio, sr, viterbi=True)\n",
        "\n",
        "    x = np.arange(0, len(audio), hop_length) / 22050.0\n",
        "    freq_interp = np.interp(x, time, frequency)\n",
        "    conf_interp = np.interp(x, time, confidence)\n",
        "    audio_interp = np.interp(x, audio_x, np.absolute(audio)) / 32768.0\n",
        "    weights = [0.5, 0.25, 0.25]\n",
        "    audio_smooth = np.convolve(audio_interp, np.array(weights)[::-1], \"same\")\n",
        "\n",
        "    conf_threshold = 0.25\n",
        "    audio_threshold = 0.0005\n",
        "    for i in range(len(freq_interp)):\n",
        "        if conf_interp[i] < conf_threshold:\n",
        "            freq_interp[i] = 0.0\n",
        "        if audio_smooth[i] < audio_threshold:\n",
        "            freq_interp[i] = 0.0\n",
        "\n",
        "    # Hack to make f0 and mel lengths equal\n",
        "    if len(audio) % hop_length == 0:\n",
        "        freq_interp = np.pad(freq_interp, pad_width=[0, 1])\n",
        "    return torch.from_numpy(freq_interp.astype(np.float32))\n",
        "\n",
        "if os.path.exists(os.path.join(output_dir, \"f0s.pt\")):\n",
        "    print(\"f0s.pt already exists; skipping\")\n",
        "else:\n",
        "    f0_data = {}\n",
        "    with open(\"allfiles.json\") as f:\n",
        "        for i, l in enumerate(f.readlines()):\n",
        "            print(str(i))\n",
        "            audio_path = json.loads(l)[\"audio_filepath\"]\n",
        "            f0_data[Path(audio_path).stem] = crepe_f0(audio_path)\n",
        "\n",
        "    # calculate f0 stats (mean & std) only for train set\n",
        "    with open(\"trainfiles.json\") as f:\n",
        "        train_ids = {Path(json.loads(l)[\"audio_filepath\"]).stem for l in f}\n",
        "    all_f0 = torch.cat([f0[f0 >= 1e-5] for f0_id, f0 in f0_data.items() if f0_id in train_ids])\n",
        "\n",
        "    F0_MEAN, F0_STD = all_f0.mean().item(), all_f0.std().item()        \n",
        "    print(\"F0_MEAN: \" + str(F0_MEAN) + \", F0_STD: \" + str(F0_STD))\n",
        "    torch.save(f0_data, os.path.join(output_dir, \"f0s.pt\"))\n",
        "    with open(os.path.join(output_dir, \"f0_info.json\"), \"w\") as f:\n",
        "        f.write(json.dumps({\"FO_MEAN\": F0_MEAN, \"F0_STD\": F0_STD}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM7-bMpKO7U2",
        "cellView": "form"
      },
      "source": [
        "#@markdown **Step 7:** Train duration predictor.\n",
        "\n",
        "#@markdown If CUDA runs out of memory, try the following:\n",
        "#@markdown * Click on Runtime -> Restart runtime, re-run step 3, and try again.\n",
        "#@markdown * If that doesn't help, reduce the batch size (default 64).\n",
        "batch_size = 64 #@param {type:\"integer\"}\n",
        "\n",
        "epochs = 20\n",
        "learning_rate = 1e-3\n",
        "min_learning_rate = 3e-6\n",
        "load_checkpoints = True\n",
        "\n",
        "import os\n",
        "from hydra.experimental import compose, initialize\n",
        "from hydra.core.global_hydra import GlobalHydra\n",
        "from omegaconf import OmegaConf\n",
        "import pytorch_lightning as pl\n",
        "from nemo.collections.common.callbacks import LogEpochTimeCallback\n",
        "from nemo.collections.tts.models import TalkNetDursModel\n",
        "from nemo.core.config import hydra_runner\n",
        "from nemo.utils.exp_manager import exp_manager\n",
        "\n",
        "def train(cfg):\n",
        "    cfg.sample_rate = 22050\n",
        "    cfg.train_dataset = \"trainfiles.json\"\n",
        "    cfg.validation_datasets = \"valfiles.json\"\n",
        "    cfg.durs_file = os.path.join(output_dir, \"durations.pt\")\n",
        "    cfg.f0_file = os.path.join(output_dir, \"f0s.pt\")\n",
        "    cfg.trainer.accelerator = \"dp\"\n",
        "    cfg.trainer.max_epochs = epochs\n",
        "    cfg.trainer.check_val_every_n_epoch = 5\n",
        "    cfg.model.train_ds.dataloader_params.batch_size = batch_size\n",
        "    cfg.model.validation_ds.dataloader_params.batch_size = batch_size\n",
        "    cfg.model.optim.lr = learning_rate\n",
        "    cfg.model.optim.sched.min_lr = min_learning_rate\n",
        "    cfg.exp_manager.exp_dir = output_dir\n",
        "\n",
        "    # Find checkpoints\n",
        "    ckpt_path = \"\"\n",
        "    if load_checkpoints:\n",
        "      path0 = os.path.join(output_dir, \"TalkNetDurs\")\n",
        "      if os.path.exists(path0):\n",
        "          path1 = sorted(os.listdir(path0))\n",
        "          for i in range(len(path1)):\n",
        "              path2 = os.path.join(path0, path1[-(1+i)], \"checkpoints\")\n",
        "              if os.path.exists(path2):\n",
        "                  match = [x for x in os.listdir(path2) if \"last.ckpt\" in x]\n",
        "                  if len(match) > 0:\n",
        "                      ckpt_path = os.path.join(path2, match[0])\n",
        "                      print(\"Resuming training from \" + match[0])\n",
        "                      break\n",
        "    \n",
        "    if ckpt_path != \"\":\n",
        "        trainer = pl.Trainer(**cfg.trainer, resume_from_checkpoint = ckpt_path)\n",
        "        model = TalkNetDursModel(cfg=cfg.model, trainer=trainer)\n",
        "    else:\n",
        "        warmstart_path = \"/content/talknet_durs.nemo\"\n",
        "        trainer = pl.Trainer(**cfg.trainer)\n",
        "        model = TalkNetDursModel.restore_from(warmstart_path, override_config_path=cfg)\n",
        "        model.set_trainer(trainer)\n",
        "        model.setup_training_data(cfg.model.train_ds)\n",
        "        model.setup_validation_data(cfg.model.validation_ds)\n",
        "        model.setup_optimization(cfg.model.optim)\n",
        "        print(\"Warm-starting from \" + warmstart_path)\n",
        "    exp_manager(trainer, cfg.get('exp_manager', None))\n",
        "    trainer.callbacks.extend([pl.callbacks.LearningRateMonitor(), LogEpochTimeCallback()])  # noqa\n",
        "    trainer.fit(model)\n",
        "\n",
        "GlobalHydra().clear()\n",
        "initialize(config_path=\"conf\")\n",
        "cfg = compose(config_name=\"talknet-durs\")\n",
        "train(cfg)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLfm00NuJfon",
        "cellView": "form"
      },
      "source": [
        "#@markdown **Step 8:** Train pitch predictor.\n",
        "\n",
        "#@markdown If CUDA runs out of memory, try the following:\n",
        "#@markdown * Click on Runtime -> Restart runtime, re-run step 3, and try again.\n",
        "#@markdown * If that doesn't help, reduce the batch size (default 64).\n",
        "batch_size = 64 #@param {type:\"integer\"}\n",
        "epochs = 50\n",
        "\n",
        "import json\n",
        "\n",
        "with open(os.path.join(output_dir, \"f0_info.json\"), \"r\") as f:\n",
        "    f0_info = json.load(f)\n",
        "    f0_mean = f0_info[\"FO_MEAN\"]\n",
        "    f0_std = f0_info[\"F0_STD\"]\n",
        "\n",
        "learning_rate = 1e-3\n",
        "min_learning_rate = 3e-6\n",
        "load_checkpoints = True\n",
        "\n",
        "import os\n",
        "from hydra.experimental import compose, initialize\n",
        "from hydra.core.global_hydra import GlobalHydra\n",
        "from omegaconf import OmegaConf\n",
        "import pytorch_lightning as pl\n",
        "from nemo.collections.common.callbacks import LogEpochTimeCallback\n",
        "from nemo.collections.tts.models import TalkNetPitchModel\n",
        "from nemo.core.config import hydra_runner\n",
        "from nemo.utils.exp_manager import exp_manager\n",
        "\n",
        "def train(cfg):\n",
        "    cfg.sample_rate = 22050\n",
        "    cfg.train_dataset = \"trainfiles.json\"\n",
        "    cfg.validation_datasets = \"valfiles.json\"\n",
        "    cfg.durs_file = os.path.join(output_dir, \"durations.pt\")\n",
        "    cfg.f0_file = os.path.join(output_dir, \"f0s.pt\")\n",
        "    cfg.trainer.accelerator = \"dp\"\n",
        "    cfg.trainer.max_epochs = epochs\n",
        "    cfg.trainer.check_val_every_n_epoch = 5\n",
        "    cfg.model.f0_mean=f0_mean\n",
        "    cfg.model.f0_std=f0_std\n",
        "    cfg.model.train_ds.dataloader_params.batch_size = batch_size\n",
        "    cfg.model.validation_ds.dataloader_params.batch_size = batch_size\n",
        "    cfg.model.optim.lr = learning_rate\n",
        "    cfg.model.optim.sched.min_lr = min_learning_rate\n",
        "    cfg.exp_manager.exp_dir = output_dir\n",
        "\n",
        "    # Find checkpoints\n",
        "    ckpt_path = \"\"\n",
        "    if load_checkpoints:\n",
        "      path0 = os.path.join(output_dir, \"TalkNetPitch\")\n",
        "      if os.path.exists(path0):\n",
        "          path1 = sorted(os.listdir(path0))\n",
        "          for i in range(len(path1)):\n",
        "              path2 = os.path.join(path0, path1[-(1+i)], \"checkpoints\")\n",
        "              if os.path.exists(path2):\n",
        "                  match = [x for x in os.listdir(path2) if \"last.ckpt\" in x]\n",
        "                  if len(match) > 0:\n",
        "                      ckpt_path = os.path.join(path2, match[0])\n",
        "                      print(\"Resuming training from \" + match[0])\n",
        "                      break\n",
        "    \n",
        "    if ckpt_path != \"\":\n",
        "        trainer = pl.Trainer(**cfg.trainer, resume_from_checkpoint = ckpt_path)\n",
        "        model = TalkNetPitchModel(cfg=cfg.model, trainer=trainer)\n",
        "    else:\n",
        "        warmstart_path = \"/content/talknet_pitch.nemo\"\n",
        "        trainer = pl.Trainer(**cfg.trainer)\n",
        "        model = TalkNetPitchModel.restore_from(warmstart_path, override_config_path=cfg)\n",
        "        model.set_trainer(trainer)\n",
        "        model.setup_training_data(cfg.model.train_ds)\n",
        "        model.setup_validation_data(cfg.model.validation_ds)\n",
        "        model.setup_optimization(cfg.model.optim)\n",
        "        print(\"Warm-starting from \" + warmstart_path)\n",
        "    exp_manager(trainer, cfg.get('exp_manager', None))\n",
        "    trainer.callbacks.extend([pl.callbacks.LearningRateMonitor(), LogEpochTimeCallback()])  # noqa\n",
        "    trainer.fit(model)\n",
        "\n",
        "GlobalHydra().clear()\n",
        "initialize(config_path=\"conf\")\n",
        "cfg = compose(config_name=\"talknet-pitch\")\n",
        "train(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9hh4WPHbCcn",
        "cellView": "form"
      },
      "source": [
        "#@markdown **Step 9:** Train spectrogram generator. 200+ epochs are recommended. \n",
        "\n",
        "#@markdown This is the slowest of the three models to train, and the hardest to\n",
        "#@markdown get good results from. If your character sounds noisy or robotic,\n",
        "#@markdown try improving the dataset, or adjusting the epochs and learning rate.\n",
        "\n",
        "epochs = 200 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown If CUDA runs out of memory, try the following:\n",
        "#@markdown * Click on Runtime -> Restart runtime, re-run step 3, and try again.\n",
        "#@markdown * If that doesn't help, reduce the batch size (default 32).\n",
        "batch_size = 32 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Advanced settings. You can probably leave these at their defaults (1e-3, 3e-6, empty, checked).\n",
        "learning_rate = 1e-3 #@param {type:\"number\"}\n",
        "min_learning_rate = 3e-6 #@param {type:\"number\"}\n",
        "pretrained_path = \"\" #@param {type:\"string\"}\n",
        "load_checkpoints = True #@param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "from hydra.experimental import compose, initialize\n",
        "from hydra.core.global_hydra import GlobalHydra\n",
        "from omegaconf import OmegaConf\n",
        "import pytorch_lightning as pl\n",
        "from nemo.collections.common.callbacks import LogEpochTimeCallback\n",
        "from nemo.collections.tts.models import TalkNetSpectModel\n",
        "from nemo.core.config import hydra_runner\n",
        "from nemo.utils.exp_manager import exp_manager\n",
        "\n",
        "def train(cfg):\n",
        "    cfg.sample_rate = 22050\n",
        "    cfg.train_dataset = \"trainfiles.json\"\n",
        "    cfg.validation_datasets = \"valfiles.json\"\n",
        "    cfg.durs_file = os.path.join(output_dir, \"durations.pt\")\n",
        "    cfg.f0_file = os.path.join(output_dir, \"f0s.pt\")\n",
        "    cfg.trainer.accelerator = \"dp\"\n",
        "    cfg.trainer.max_epochs = epochs\n",
        "    cfg.trainer.check_val_every_n_epoch = 5\n",
        "    cfg.model.train_ds.dataloader_params.batch_size = batch_size\n",
        "    cfg.model.validation_ds.dataloader_params.batch_size = batch_size\n",
        "    cfg.model.optim.lr = learning_rate\n",
        "    cfg.model.optim.sched.min_lr = min_learning_rate\n",
        "    cfg.exp_manager.exp_dir = output_dir\n",
        "\n",
        "    # Find checkpoints\n",
        "    ckpt_path = \"\"\n",
        "    if load_checkpoints:\n",
        "      path0 = os.path.join(output_dir, \"TalkNetSpect\")\n",
        "      if os.path.exists(path0):\n",
        "          path1 = sorted(os.listdir(path0))\n",
        "          for i in range(len(path1)):\n",
        "              path2 = os.path.join(path0, path1[-(1+i)], \"checkpoints\")\n",
        "              if os.path.exists(path2):\n",
        "                  match = [x for x in os.listdir(path2) if \"last.ckpt\" in x]\n",
        "                  if len(match) > 0:\n",
        "                      ckpt_path = os.path.join(path2, match[0])\n",
        "                      print(\"Resuming training from \" + match[0])\n",
        "                      break\n",
        "    \n",
        "    if ckpt_path != \"\":\n",
        "        trainer = pl.Trainer(**cfg.trainer, resume_from_checkpoint = ckpt_path)\n",
        "        model = TalkNetSpectModel(cfg=cfg.model, trainer=trainer)\n",
        "    else:\n",
        "        if pretrained_path != \"\":\n",
        "            warmstart_path = pretrained_path\n",
        "        else:\n",
        "            warmstart_path = \"/content/talknet_spect.nemo\"\n",
        "        trainer = pl.Trainer(**cfg.trainer)\n",
        "        model = TalkNetSpectModel.restore_from(warmstart_path, override_config_path=cfg)\n",
        "        model.set_trainer(trainer)\n",
        "        model.setup_training_data(cfg.model.train_ds)\n",
        "        model.setup_validation_data(cfg.model.validation_ds)\n",
        "        model.setup_optimization(cfg.model.optim)\n",
        "        print(\"Warm-starting from \" + warmstart_path)\n",
        "    exp_manager(trainer, cfg.get('exp_manager', None))\n",
        "    trainer.callbacks.extend([pl.callbacks.LearningRateMonitor(), LogEpochTimeCallback()])  # noqa\n",
        "    trainer.fit(model)\n",
        "\n",
        "GlobalHydra().clear()\n",
        "initialize(config_path=\"conf\")\n",
        "cfg = compose(config_name=\"talknet-spect\")\n",
        "train(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajfyfz2p9Ior",
        "cellView": "form"
      },
      "source": [
        "#@markdown **Step 10:** Generate GTA spectrograms. This will help HiFi-GAN learn what your TalkNet model sounds like.\n",
        "\n",
        "#@markdown If this step fails, make sure you've finished training the spectrogram generator.\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from nemo.collections.tts.models import TalkNetSpectModel\n",
        "import shutil\n",
        "\n",
        "def fix_paths(inpath):\n",
        "    output = \"\"\n",
        "    with open(inpath, \"r\", encoding=\"utf8\") as f:\n",
        "        for l in f.readlines():\n",
        "            if l[:5].lower() != \"wavs/\":\n",
        "                output += \"wavs/\" + l\n",
        "            else:\n",
        "                output += l\n",
        "    with open(inpath, \"w\", encoding=\"utf8\") as w:\n",
        "        w.write(output)\n",
        "\n",
        "shutil.copyfile(train_filelist, \"/content/hifi-gan/training.txt\")\n",
        "shutil.copyfile(val_filelist, \"/content/hifi-gan/validation.txt\")\n",
        "fix_paths(\"/content/hifi-gan/training.txt\")\n",
        "fix_paths(\"/content/hifi-gan/validation.txt\")\n",
        "fix_paths(\"/content/allfiles.txt\")\n",
        "\n",
        "os.chdir('/content')\n",
        "indir = \"wavs\"\n",
        "outdir = \"hifi-gan/wavs\"\n",
        "if not os.path.exists(outdir):\n",
        "    os.mkdir(outdir)\n",
        "\n",
        "model_path = \"\"\n",
        "path0 = os.path.join(output_dir, \"TalkNetSpect\")\n",
        "if os.path.exists(path0):\n",
        "    path1 = sorted(os.listdir(path0))\n",
        "    for i in range(len(path1)):\n",
        "        path2 = os.path.join(path0, path1[-(1+i)], \"checkpoints\")\n",
        "        if os.path.exists(path2):\n",
        "            match = [x for x in os.listdir(path2) if \"TalkNetSpect.nemo\" in x]\n",
        "            if len(match) > 0:\n",
        "                model_path = os.path.join(path2, match[0])\n",
        "                break\n",
        "assert model_path != \"\", \"TalkNetSpect.nemo not found\"\n",
        "\n",
        "dur_path = os.path.join(output_dir, \"durations.pt\")\n",
        "f0_path = os.path.join(output_dir, \"f0s.pt\")\n",
        "\n",
        "model = TalkNetSpectModel.restore_from(model_path)\n",
        "model.eval()\n",
        "with open(\"allfiles.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    dataset = f.readlines()\n",
        "durs = torch.load(dur_path)\n",
        "f0s = torch.load(f0_path)\n",
        "\n",
        "for x in tqdm(dataset):\n",
        "    x_name = os.path.splitext(os.path.basename(x.split(\"|\")[0].strip()))[0]\n",
        "    x_tokens = model.parse(text=x.split(\"|\")[1].strip())\n",
        "    x_durs = (\n",
        "        torch.stack(\n",
        "            (\n",
        "                durs[x_name][\"blanks\"],\n",
        "                torch.cat((durs[x_name][\"tokens\"], torch.zeros(1).int())),\n",
        "            ),\n",
        "            dim=1,\n",
        "        )\n",
        "        .view(-1)[:-1]\n",
        "        .view(1, -1)\n",
        "        .to(\"cuda:0\")\n",
        "    )\n",
        "    x_f0s = f0s[x_name].view(1, -1).to(\"cuda:0\")\n",
        "    x_spect = model.force_spectrogram(tokens=x_tokens, durs=x_durs, f0=x_f0s)\n",
        "    rel_path = os.path.splitext(x.split(\"|\")[0].strip())[0][5:]\n",
        "    abs_dir = os.path.join(outdir, os.path.dirname(rel_path))\n",
        "    if abs_dir != \"\" and not os.path.exists(abs_dir):\n",
        "        os.makedirs(abs_dir, exist_ok=True)\n",
        "    np.save(os.path.join(outdir, rel_path + \".npy\"), x_spect.detach().cpu().numpy())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVBjGhRB9hUJ",
        "cellView": "form"
      },
      "source": [
        "#@markdown **Step 11:** Train HiFi-GAN. 2,000+ steps are recommended.\n",
        "#@markdown Stop this cell to finish training the model.\n",
        "\n",
        "#@markdown If CUDA runs out of memory, click on Runtime -> Restart runtime, re-run step 3, and try again.\n",
        "#@markdown If this step still fails to start, make sure step 10 finished successfully.\n",
        "\n",
        "#@markdown Note: If the training process starts at step 2500000, delete the HiFiGAN folder and try again.\n",
        "\n",
        "import gdown\n",
        "d = 'https://drive.google.com/uc?id='\n",
        "\n",
        "os.chdir('/content/hifi-gan')\n",
        "assert os.path.exists(\"wavs\"), \"Spectrogram folder not found\"\n",
        "\n",
        "if not os.path.exists(os.path.join(output_dir, \"HiFiGAN\")):\n",
        "    os.makedirs(os.path.join(output_dir, \"HiFiGAN\"))\n",
        "if not os.path.exists(os.path.join(output_dir, \"HiFiGAN\", \"do_00000000\")):\n",
        "    print(\"Downloading universal model...\")\n",
        "    gdown.download(d+\"1qpgI41wNXFcH-iKq1Y42JlBC9j0je8PW\", os.path.join(output_dir, \"HiFiGAN\", \"g_00000000\"), quiet=False)\n",
        "    gdown.download(d+\"1O63eHZR9t1haCdRHQcEgMfMNxiOciSru\", os.path.join(output_dir, \"HiFiGAN\", \"do_00000000\"), quiet=False)\n",
        "    start_from_universal = \"--warm_start True \"\n",
        "else:\n",
        "    start_from_universal = \"\"\n",
        "\n",
        "!python train.py --fine_tuning True --config config_v1b.json \\\n",
        "{start_from_universal} \\\n",
        "--checkpoint_interval 250 --checkpoint_path \"{os.path.join(output_dir, 'HiFiGAN')}\" \\\n",
        "--input_training_file \"/content/hifi-gan/training.txt\" \\\n",
        "--input_validation_file \"/content/hifi-gan/validation.txt\" \\\n",
        "--input_wavs_dir \"..\" --input_mels_dir \"wavs\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OtwfrTT-blU",
        "cellView": "form"
      },
      "source": [
        "#@markdown **Step 12:** Package the models. They'll be saved to the output directory as [character_name]_TalkNet.zip.\n",
        "\n",
        "character_name = \"Character\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown When done, generate a Drive share link, with permissions set to \"Anyone with the link\". \n",
        "#@markdown You can then use it with the [Controllable TalkNet notebook](https://colab.research.google.com/drive/1aj6Jk8cpRw7SsN3JSYCv57CrR6s0gYPB) \n",
        "#@markdown by selecting \"Custom model\" as your character.\n",
        "\n",
        "#@markdown This cell will also move the training checkpoints and logs to the trash.\n",
        "#@markdown That should free up roughly 2 GB of space on your Drive (remember to empty your trash).\n",
        "#@markdown If you wish to keep them, uncheck this box.\n",
        "\n",
        "delete_checkpoints = True #@param {type:\"boolean\"}\n",
        "\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def find_talknet(model_dir):\n",
        "    ckpt_path = \"\"\n",
        "    path0 = os.path.join(output_dir, model_dir)\n",
        "    if os.path.exists(path0):\n",
        "        path1 = sorted(os.listdir(path0))\n",
        "        for i in range(len(path1)):\n",
        "            path2 = os.path.join(path0, path1[-(1+i)], \"checkpoints\")\n",
        "            if os.path.exists(path2):\n",
        "                match = [x for x in os.listdir(path2) if \".nemo\" in x]\n",
        "                if len(match) > 0:\n",
        "                    ckpt_path = os.path.join(path2, match[0])\n",
        "                    break\n",
        "    assert ckpt_path != \"\", \"Couldn't find \" + model_dir\n",
        "    return ckpt_path\n",
        "\n",
        "durs_path = find_talknet(\"TalkNetDurs\")\n",
        "pitch_path = find_talknet(\"TalkNetPitch\")\n",
        "spect_path = find_talknet(\"TalkNetSpect\")\n",
        "assert os.path.exists(os.path.join(output_dir, \"HiFiGAN\", \"g_00000000\")), \"Couldn't find HiFi-GAN\"\n",
        "\n",
        "zip = ZipFile(os.path.join(output_dir, character_name + \"_TalkNet.zip\"), 'w')\n",
        "zip.write(durs_path, \"TalkNetDurs.nemo\")\n",
        "zip.write(pitch_path, \"TalkNetPitch.nemo\")\n",
        "zip.write(spect_path, \"TalkNetSpect.nemo\")\n",
        "zip.write(os.path.join(output_dir, \"HiFiGAN\", \"g_00000000\"), \"hifiganmodel\")\n",
        "zip.write(os.path.join(output_dir, \"HiFiGAN\", \"config.json\"), \"config.json\")\n",
        "zip.write(os.path.join(output_dir, \"f0_info.json\"), \"f0_info.json\")\n",
        "zip.close()\n",
        "print(\"Archived model to \" + os.path.join(output_dir, character_name + \"_TalkNet.zip\"))\n",
        "\n",
        "if delete_checkpoints:\n",
        "    shutil.rmtree((os.path.join(output_dir, \"TalkNetDurs\")))\n",
        "    shutil.rmtree((os.path.join(output_dir, \"TalkNetPitch\")))\n",
        "    shutil.rmtree((os.path.join(output_dir, \"TalkNetSpect\")))\n",
        "    shutil.rmtree((os.path.join(output_dir, \"HiFiGAN\")))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}